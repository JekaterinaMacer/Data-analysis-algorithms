# Data analysis algorithms
Урок 1. Алгоритм линейной регрессии. Градиентный спуск.


1. [Вывод аналитической формулы решения уравнения линейной регрессии](https://habr.com/ru/company/ods/blog/323890/#metod-naimenshih-kvadratov) (см. пункт 1.2)
2. [Математическое описание метода градиентного спуска](http://www.machinelearning.ru/wiki/index.php?title=%D0%9C%D0%B5%D1%82%D0%BE%D0%B4_%D0%B3%D1%80%D0%B0%D0%B4%D0%B8%D0%B5%D0%BD%D1%82%D0%BD%D0%BE%D0%B3%D0%BE_%D1%81%D0%BF%D1%83%D1%81%D0%BA%D0%B0)
3. [Документация NumPy](https://docs.scipy.org/doc/numpy-1.16.0/reference/routines.html)

## Summary

* Линейная регрессия - простой, но зачастую эффективный, способ приближать вещественную целевую переменную через линейную комбинацию признаков
* Решение регрессии - МНК, можно решать аналитически, но на практике - градиентный спуск (GD, Gradient Descent)
* MSE удобна для градиентного спуска, так как дифференцируема
* Максимальное качество градиентного спуска достигается малыми шагами и большим кол-вом итераций

### Опеределения
*Машинное обучение*

**Машинное обучение** — дисциплина, заключающаяся в извлечении знаний из известных данных.

**Признак** — это индивидуальное измеримое свойство или характеристика наблюдения.

**Обучающая выборка** — набор структурированных данных, используемый для обучения моделей.

**Обучение с учителем** — это направление машинного обучения, объединяющее алгоритмы и методы построения моделей на основе множества примеров, содержащих пары "известный вход - известный выход".

**Обучение без учителя** — направление машинного обучения, в которой для коррекции параметров обучаемой модели не используется целевая функция. Иными словами, в обучающих примерах при обучении без учителя не нужно иметь заранее заданные выходы модели.

**Обучение с подкреплением** — раздел машинного обучения, изучающий поведение интеллектуальных агентов, действующих в некоторой среде и принимающих решения.
___________

_Линейные модели_

**Линейные модели** — такие модели, которые сводятся к суммированию значений признаков с некоторыми весами

**Линейная регрессия** — модель зависимости переменной x от одной или нескольких других переменных (факторов, регрессоров, независимых переменных) с линейной функцией зависимости.

**Метод наименьших квадратов** — способ вычисления весов линейной модели путем минимизации среднеквадратичного отклонения.
___________

_Градиентный спуск_

**Градиент функции** — $n$-мерный вектор из частных производных. Задает направление наискорейшего роста функции. $$ \nabla f(x_{1},...,x_{d}) = \left(\frac{\partial f}{\partial x_{i}}\right)^{d}_{i=1}.$$

**Градиентный спуск** — метод нахождения локального экстремума функции (минимума или максимума) с помощью движения вдоль градиента.
